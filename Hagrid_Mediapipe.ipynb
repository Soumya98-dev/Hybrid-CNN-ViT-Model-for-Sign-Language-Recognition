{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec724559-5738-4a96-b007-1c2636140183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mediapipe in /opt/anaconda3/lib/python3.12/site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: jaxlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv opencv-python pillow datasets tqdm \n",
    "!pip install mediapipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96f6caf-bd7f-4517-996c-b3d31ee14a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 7635k  100 7635k    0     0  14.4M      0 --:--:-- --:--:-- --:--:-- 14.5M\n"
     ]
    }
   ],
   "source": [
    "!curl -o hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4685faeb-e612-4cf9-b3e4-528884a936a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumyadeepchatterjee/Desktop/WayneState/Winter2025/FinalProject/Hybrid-CNN-ViT-Model-for-Sign-Language-Recognition/yolov8_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import math\n",
    "import traceback\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6afae0-9fef-44a8-8487-a392e7e74792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cj-mills/hagrid-sample-500k-384p\", split=\"train\", streaming=True)\n",
    "\n",
    "output_dir = Path(\"hand_crops_mediapipe\") \n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9370b4e-3b1c-4c8c-b426-27075385b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with MediaPipe...\n",
      "MediaPipe Hand Landmarker initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744849548.741822 3386130 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2 Pro\n",
      "W0000 00:00:1744849548.753776 3423851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744849548.760574 3423851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 images. Stopping.\n",
      "Processing finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = 'hand_landmarker.task'\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence=0.5,\n",
    "    min_hand_presence_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "def calculate_bounding_box(image_width, image_height, landmarks, padding=5):\n",
    "    if not landmarks: return None\n",
    "    x_coords = [lm.x * image_width for lm in landmarks]\n",
    "    y_coords = [lm.y * image_height for lm in landmarks]\n",
    "    if not x_coords or not y_coords: return None \n",
    "    x_min = int(min(x_coords) - padding)\n",
    "    y_min = int(min(y_coords) - padding)\n",
    "    x_max = int(max(x_coords) + padding)\n",
    "    y_max = int(max(y_coords) + padding)\n",
    "    x1 = max(0, x_min); y1 = max(0, y_min)\n",
    "    x2 = min(image_width, x_max); y2 = min(image_height, y_max)\n",
    "    if x1 >= x2 or y1 >= y2: return None\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "print(\"Starting processing with MediaPipe...\")\n",
    "try:\n",
    "    with HandLandmarker.create_from_options(options) as landmarker:\n",
    "        print(\"MediaPipe Hand Landmarker initialized successfully.\")\n",
    "        processed_count = 0\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            if processed_count >= 50:\n",
    "                print(\"Processed 50 images. Stopping.\")\n",
    "                break\n",
    "            try:\n",
    "                pil_img = sample[\"image\"].convert(\"RGB\")\n",
    "                img_np = np.array(pil_img)\n",
    "                h_img, w_img, _ = img_np.shape\n",
    "\n",
    "                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_np)\n",
    "\n",
    "                detection_result = landmarker.detect(mp_image)\n",
    "\n",
    "                \n",
    "                if detection_result and detection_result.hand_landmarks:\n",
    "                    num_hands_detected = len(detection_result.hand_landmarks)\n",
    "                    \n",
    "\n",
    "                    for hand_idx, hand_landmarks in enumerate(detection_result.hand_landmarks):\n",
    "                        bbox = calculate_bounding_box(w_img, h_img, hand_landmarks)\n",
    "                        if bbox is None: continue\n",
    "                        x1, y1, x2, y2 = bbox\n",
    "                        hand_crop = img_np[y1:y2, x1:x2]\n",
    "                        if hand_crop.size == 0: continue\n",
    "                        hand_crop_resized = cv2.resize(hand_crop, (224, 224))\n",
    "                        handedness = \"unknown\"\n",
    "                        if detection_result.handedness and hand_idx < len(detection_result.handedness):\n",
    "                            handedness = detection_result.handedness[hand_idx][0].category_name.lower()\n",
    "                        out_path = output_dir / f\"image{idx}_hand{hand_idx}_{handedness}.jpg\"\n",
    "                        cv2.imwrite(str(out_path), cv2.cvtColor(hand_crop_resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                    processed_count += 1\n",
    "\n",
    "            except Exception as e_inner:\n",
    "                print(f\"âŒ Error processing image {idx}: {e_inner}\")\n",
    "                traceback.print_exc() \n",
    "\n",
    "except Exception as e_outer:\n",
    "    print(f\"Error initializing MediaPipe or during loop setup: {e_outer}\")\n",
    "    traceback.print_exc() \n",
    "\n",
    "print(\"Processing finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc509ae-4e6b-4dca-836a-0aadaeaf34fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YOLOv8)",
   "language": "python",
   "name": "yolov8_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
